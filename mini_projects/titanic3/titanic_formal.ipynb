{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_titanic_train():\n",
    "    \n",
    "    df = pd.read_csv('titanic_train.csv')\n",
    "    \n",
    "    fill_dict = {}\n",
    "    \n",
    "    df.drop(columns=['PassengerId'], inplace=True)\n",
    "    Pclass_fill = df['Pclass'].mode()[0]\n",
    "    df['Pclass'].fillna(Pclass_fill, inplace=True)\n",
    "    fill_dict['Pclass'] = Pclass_fill\n",
    "    \n",
    "    Name_fill = \"no_name. is missing value\"\n",
    "    df['Name'].fillna(Name_fill, inplace=True)\n",
    "    fill_dict['Name'] = Name_fill\n",
    "    \n",
    "    df['title'] = df['Name'].apply(lambda x: x.split('.')[0].split()[-1].strip().lower())\n",
    "    common_titles = ['mr','mrs','miss','master']\n",
    "    df['title'] = df['title'].apply(lambda x: x if x in common_titles else 'special_title')\n",
    "    df.drop(columns=['Name'], inplace=True)\n",
    "    \n",
    "    def fill_sex(x):\n",
    "        if pd.isnull(x['Sex']):\n",
    "            if x['title'] in ['mrs','miss']:\n",
    "                return 'female'\n",
    "            else:\n",
    "                return 'male'\n",
    "        else:\n",
    "            return x['Sex']\n",
    "    \n",
    "    df['Sex'] = df.apply(lambda x: fill_sex(x), axis=1)\n",
    "    \n",
    "    age_fill = df.groupby(['Pclass','Sex']).mean()['Age']\n",
    "    df['Age'] = round(df.apply(lambda x: age_fill[x['Pclass']][x['Sex']] if pd.isnull(x['Age']) else x['Age'], axis=1), 2)\n",
    "    fill_dict['Age'] = age_fill\n",
    "    \n",
    "    SibSp_fill = df['SibSp'].mode()[0]\n",
    "    df['SibSp'].fillna(SibSp_fill, inplace=True)\n",
    "    fill_dict['SibSp'] = SibSp_fill\n",
    "    \n",
    "    Parch_fill = df['Parch'].mode()[0]\n",
    "    df['Parch'].fillna(Parch_fill, inplace=True)\n",
    "    fill_dict['Parch'] = Parch_fill\n",
    "    \n",
    "    df['Ticket'].fillna(\"9\", inplace=True)\n",
    "    \n",
    "    fare_fill = df.groupby(['Pclass','Sex']).mean()['Fare']\n",
    "    df['Fare'] = df.apply(lambda x: fare_fill[x['Pclass']][x['Sex']] if pd.isnull(x['Fare']) else x['Fare'], axis=1)\n",
    "    fill_dict['Fare'] = fare_fill\n",
    "    \n",
    "    df['Cabin'] = df['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    \n",
    "    embarked_fill = df['Embarked'].mode()[0]\n",
    "    df['Embarked'].fillna(embarked_fill, inplace=True)\n",
    "    fill_dict['Embarked'] = embarked_fill\n",
    "    \n",
    "    df['age_group'] = pd.cut(df['Age'], bins=[0,5,14,60,100], labels=['infant','child','adult','old'])\n",
    "    df['family_size'] = df['SibSp'] + df['Parch']\n",
    "    df['ticket_feat'] = df['Ticket'].apply(lambda x: 'other_num' if x[0] in ['4','5','6','7','8','9'] else x[0])\n",
    "    df.drop(columns=['Ticket'], inplace=True)\n",
    "    df['fare_tier'] = pd.cut(df['Fare'], bins=[0,50,1000], labels=['economical','expensive'], include_lowest=True)\n",
    "    \n",
    "    df['Fare'] = round(df['Fare'].apply(lambda x:np.log(x+1)), 2)\n",
    "    \n",
    "    sex_dummies = pd.get_dummies(df['Sex'], prefix='sex', drop_first=True)\n",
    "    embarked_dummies = pd.get_dummies(df['Embarked'], prefix='embarked', drop_first=True)\n",
    "    title_dummies = pd.get_dummies(df['title'], prefix='title', drop_first=True)\n",
    "    age_group_dummies = pd.get_dummies(df['age_group'], prefix='age_group', drop_first=True)\n",
    "    ticket_feat_dummies = pd.get_dummies(df['ticket_feat'], prefix='ticket', drop_first=True)\n",
    "    fare_tier_dummies = pd.get_dummies(df['fare_tier'], prefix='fare', drop_first=True)\n",
    "    \n",
    "    df = pd.concat([df,sex_dummies,embarked_dummies,title_dummies,age_group_dummies,ticket_feat_dummies,fare_tier_dummies], axis=1)\n",
    "    df.drop(columns=['Sex','Embarked','title','age_group','ticket_feat','fare_tier'], inplace=True)\n",
    "    \n",
    "    return df, fill_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df, fill_dict = process_titanic_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_titanic_test(fill_dict):\n",
    "    \n",
    "    df = pd.read_csv('titanic_test.csv')\n",
    "    \n",
    "    pass_id_array = df['PassengerId'].values\n",
    "    df.drop(columns=['PassengerId'], inplace=True)\n",
    "    \n",
    "    for feat in ['Pclass','Name','SibSp','Parch','Embarked']:\n",
    "        df[feat].fillna(fill_dict[feat], inplace=True)\n",
    "    \n",
    "    df['title'] = df['Name'].apply(lambda x: x.split('.')[0].split()[-1].strip().lower())\n",
    "    common_titles = ['mr','mrs','miss','master']\n",
    "    df['title'] = df['title'].apply(lambda x: x if x in common_titles else 'special_title')\n",
    "    df.drop(columns=['Name'], inplace=True)\n",
    "    \n",
    "    def fill_sex(x):\n",
    "        if pd.isnull(x['Sex']):\n",
    "            if x['title'] in ['mrs','miss']:\n",
    "                return 'female'\n",
    "            else:\n",
    "                return 'male'\n",
    "        else:\n",
    "            return x['Sex']\n",
    "    \n",
    "    df['Sex'] = df.apply(lambda x: fill_sex(x), axis=1)\n",
    "    df['Age'] = round(df.apply(lambda x: fill_dict['Age'][x['Pclass']][x['Sex']] if pd.isnull(x['Age']) else x['Age'], axis=1), 2)\n",
    "    df['Ticket'].fillna(\"9\", inplace=True)\n",
    "    df['Fare'] = df.apply(lambda x: fill_dict['Fare'][x['Pclass']][x['Sex']] if pd.isnull(x['Fare']) else x['Fare'], axis=1)\n",
    "    df['Cabin'] = df['Cabin'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "    \n",
    "    df['age_group'] = pd.cut(df['Age'], bins=[0,5,14,60,100], labels=['infant','child','adult','old'])\n",
    "    df['family_size'] = df['SibSp'] + df['Parch']\n",
    "    df['ticket_feat'] = df['Ticket'].apply(lambda x: 'other_num' if x[0] in ['4','5','6','7','8','9'] else x[0])\n",
    "    df.drop(columns=['Ticket'], inplace=True)\n",
    "    df['fare_tier'] = pd.cut(df['Fare'], bins=[0,50,1000], labels=['economical','expensive'], include_lowest=True)\n",
    "    \n",
    "    df['Fare'] = round(df['Fare'].apply(lambda x:np.log(x+1)), 2)\n",
    "    \n",
    "    sex_dummies = pd.get_dummies(df['Sex'], prefix='sex', drop_first=True)\n",
    "    embarked_dummies = pd.get_dummies(df['Embarked'], prefix='embarked', drop_first=True)\n",
    "    title_dummies = pd.get_dummies(df['title'], prefix='title', drop_first=True)\n",
    "    age_group_dummies = pd.get_dummies(df['age_group'], prefix='age_group', drop_first=True)\n",
    "    ticket_feat_dummies = pd.get_dummies(df['ticket_feat'], prefix='ticket', drop_first=True)\n",
    "    fare_tier_dummies = pd.get_dummies(df['fare_tier'], prefix='fare', drop_first=True)\n",
    "    \n",
    "    df = pd.concat([df,sex_dummies,embarked_dummies,title_dummies,age_group_dummies,ticket_feat_dummies,fare_tier_dummies], axis=1)\n",
    "    df.drop(columns=['Sex','Embarked','title','age_group','ticket_feat','fare_tier'], inplace=True)\n",
    "    \n",
    "    return df, pass_id_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testdf, pass_id_array = process_titanic_test(fill_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>family_size</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "      <th>...</th>\n",
       "      <th>ticket_3</th>\n",
       "      <th>ticket_A</th>\n",
       "      <th>ticket_C</th>\n",
       "      <th>ticket_F</th>\n",
       "      <th>ticket_L</th>\n",
       "      <th>ticket_P</th>\n",
       "      <th>ticket_S</th>\n",
       "      <th>ticket_W</th>\n",
       "      <th>ticket_other_num</th>\n",
       "      <th>fare_expensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch  Fare  Cabin  family_size  sex_male  embarked_Q  \\\n",
       "0       3  34.5      0      0  2.18      0            0         1           1   \n",
       "1       3  47.0      1      0  2.08      0            1         0           0   \n",
       "2       2  62.0      0      0  2.37      0            0         1           1   \n",
       "3       3  27.0      0      0  2.27      0            0         1           0   \n",
       "4       3  22.0      1      1  2.59      0            2         0           0   \n",
       "\n",
       "   embarked_S       ...        ticket_3  ticket_A  ticket_C  ticket_F  \\\n",
       "0           0       ...               1         0         0         0   \n",
       "1           1       ...               1         0         0         0   \n",
       "2           0       ...               0         0         0         0   \n",
       "3           1       ...               1         0         0         0   \n",
       "4           1       ...               1         0         0         0   \n",
       "\n",
       "   ticket_L  ticket_P  ticket_S  ticket_W  ticket_other_num  fare_expensive  \n",
       "0         0         0         0         0                 0               0  \n",
       "1         0         0         0         0                 0               0  \n",
       "2         0         0         0         0                 0               0  \n",
       "3         0         0         0         0                 0               0  \n",
       "4         0         0         0         0                 0               0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['Survived']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algos = [LogisticRegression(), DecisionTreeClassifier(), RandomForestClassifier(), SVC()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "[ 0.81481481  0.81481481  0.82828283]\n",
      "\n",
      "\n",
      "DecisionTreeClassifier:\n",
      "[ 0.77441077  0.79461279  0.8013468 ]\n",
      "\n",
      "\n",
      "RandomForestClassifier:\n",
      "[ 0.79124579  0.83501684  0.81144781]\n",
      "\n",
      "\n",
      "SVC:\n",
      "[ 0.82154882  0.81144781  0.83501684]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for algo in algos:\n",
    "    model = make_pipeline(StandardScaler(), algo)\n",
    "    score = cross_val_score(model, df.drop(columns = ['Survived']), df['Survived'])\n",
    "    print(\"{}:\\n{}\\n\\n\".format(str(algo).split('(')[0], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "[ 0.79124579  0.83164983  0.81818182]\n",
      "\n",
      "\n",
      "DecisionTreeClassifier:\n",
      "[ 0.77104377  0.81818182  0.80808081]\n",
      "\n",
      "\n",
      "RandomForestClassifier:\n",
      "[ 0.76767677  0.8013468   0.82154882]\n",
      "\n",
      "\n",
      "SVC:\n",
      "[ 0.81481481  0.84511785  0.83501684]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for algo in algos:\n",
    "    model = make_pipeline(algo)\n",
    "    score = cross_val_score(model, df.drop(columns = ['Survived','Age','Fare']), df['Survived'])\n",
    "    print(\"{}:\\n{}\\n\\n\".format(str(algo).split('(')[0], score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76767677,  0.83501684,  0.82491582])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(RandomForestClassifier(n_estimators=20), df.drop(columns = ['Survived']), df['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79461279,  0.82154882,  0.81481481])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(), df.drop(columns = ['Survived']), df['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
