{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ames_feat_transform.py\n",
    "def trans_features(df):\n",
    "    \n",
    "    # drop irrelevant features\n",
    "    drop_list = pd.read_excel('data/old_features_ames.xlsx', usecols=\"A,D\").dropna()['Feature'].tolist()\n",
    "    df.drop(columns=drop_list, inplace=True)\n",
    "    \n",
    "    # fill missing values\n",
    "    ofdf = pd.read_excel('data/old_features_ames.xlsx', usecols=\"A,F\")\n",
    "    ofdf = ofdf[~ofdf['Feature'].isin(drop_list)]\n",
    "    ofdf.dropna(inplace=True) #only target 'SalePrice' has NaN for 'Missing Handle'\n",
    "    median_list = ofdf[ofdf['Missing Handle']=='median']['Feature'].tolist()\n",
    "    mode_list = ofdf[ofdf['Missing Handle']=='mode']['Feature'].tolist()\n",
    "    \n",
    "    for med in median_list:\n",
    "        df[med].fillna(df[med].median(), inplace=True)\n",
    "    \n",
    "    for mod in mode_list:\n",
    "        df[mod].fillna(df[mod].mode()[0], inplace=True)\n",
    "    \n",
    "    cusdf = pd.read_excel('data/old_features_ames.xlsx', usecols=\"A,G\")\n",
    "    cusdf.dropna(inplace=True)\n",
    "    for index, row in cusdf.iterrows():\n",
    "        df[row['Feature']].fillna(row['Missing Custom'], inplace=True)\n",
    "    \n",
    "    \n",
    "    # new features\n",
    "    df['UnfinishedBasement'] = df['BsmtUnfSF'].apply(lambda x: 0 if x==0 else 1)\n",
    "    df['SecondFloor'] = df['2ndFlrSF'].apply(lambda x: 0 if x==0 else 1)\n",
    "    df['TotalFullBath'] = df['BsmtFullBath'] + df['FullBath']\n",
    "    df['TotalHalfBath'] = df['BsmtHalfBath'] + df['HalfBath']\n",
    "    df['OtherRmsAbvGrd'] = df['TotRmsAbvGrd'] - df['BedroomAbvGr']\n",
    "    \n",
    "    # transformations\n",
    "    log_list = ['LotFrontage','LotArea','TotalBsmtSF','1stFlrSF','GrLivArea']\n",
    "    for logf in log_list:\n",
    "        df[logf] = df[logf].apply(lambda x: np.log(x+1))\n",
    "    \n",
    "    mssubclass_mapper = {\n",
    "        20 : 'mssub1',\n",
    "        30 : 'mssub2',\n",
    "        40 : 'mssub3',\n",
    "        45 : 'mssub4',\n",
    "        50 : 'mssub5',\n",
    "        60 : 'mssub6',\n",
    "        70 : 'mssub7',\n",
    "        75 : 'mssub8',\n",
    "        80 : 'mssub9',\n",
    "        85 : 'mssub10',\n",
    "        90 : 'mssub11',\n",
    "        120 : 'mssub12',\n",
    "        150 : 'mssub13',\n",
    "        160 : 'mssub14',\n",
    "        180 : 'mssub15',\n",
    "        190 : 'mssub16'\n",
    "    }\n",
    "    \n",
    "    df['MSSubClass'].replace(mssubclass_mapper, inplace=True)\n",
    "    #df['MoSold'].replace(mosold_mapper, inplace=True)\n",
    "    \n",
    "    df['GarageYrBlt'] = df['GarageYrBlt'] - 1890\n",
    "    df['YearBuilt'] = df['YearBuilt'] - 1850\n",
    "    df['YearRemodAdd'] = df['YearRemodAdd'] - 1940\n",
    "    \n",
    "    def change_categories(x, cat_dict):\n",
    "        if x in cat_dict.keys():\n",
    "            return cat_dict[x]\n",
    "        elif 'rare_cat_name' in cat_dict.keys():\n",
    "            return cat_dict['rare_cat_name']\n",
    "        else:\n",
    "            return 'others'\n",
    "    \n",
    "    \n",
    "    df['MSZoning'] = df['MSZoning'].apply(lambda x: change_categories(x, {'RL':'RL','FV':'FV'}))\n",
    "    df['LotShape'] = df['LotShape'].apply(lambda x: change_categories(x, {'Reg':'Reg','rare_cat_name':'Irreg'}))\n",
    "    df['LandContour'] = df['LandContour'].apply(lambda x: change_categories(x, {'Lvl':'Lvl','Bnk':'Bnk'}))\n",
    "    df['LotConfig'] = df['LotConfig'].apply(lambda x: change_categories(x, {'Inside':'Inside','FR2':'FR2','Corner':'Corner','rare_cat_name':'CulDFR3'}))\n",
    "    df['Neighborhood'] = df['Neighborhood'].apply(lambda x: change_categories(x, {'Blmngtn': 'nhood2',  'Blueste': 'nhood3',  'BrDale': 'nhood3',  'BrkSide': 'nhood3',  'ClearCr': 'nhood2',  'CollgCr': 'nhood2',  'Crawfor': 'nhood2',  'Edwards': 'nhood3',  'Gilbert': 'nhood2',  'IDOTRR': 'nhood3',  'MeadowV': 'nhood3',  'Mitchel': 'nhood3',  'NAmes': 'nhood3',  'NPkVill': 'nhood3',  'NWAmes': 'nhood2',  'NoRidge': 'nhood1',  'NridgHt': 'nhood1',  'OldTown': 'nhood3',  'SWISU': 'nhood3',  'Sawyer': 'nhood3',  'SawyerW': 'nhood2',  'Somerst': 'nhood2',  'StoneBr': 'nhood1',  'Timber': 'nhood2',  'Veenker': 'nhood2'}))\n",
    "    df['Exterior1st'] = df['Exterior1st'].apply(lambda x: change_categories(x, {'AsbShng': 'Ext1_low',  'AsphShn': 'Ext1_low',  'BrkComm': 'Ext1_low',  'BrkFace': 'Ext1_low',  'CBlock': 'Ext1_low',  'CemntBd': 'Ext1_high',  'HdBoard': 'Ext1_low',  'ImStucc': 'Ext1_high',  'MetalSd': 'Ext1_low',  'Plywood': 'Ext1_low',  'Stone': 'Ext1_high',  'Stucco': 'Ext1_low',  'VinylSd': 'Ext1_high',  'Wd Sdng': 'Ext1_low',  'WdShing': 'Ext1_low'}))\n",
    "    df['Exterior2nd'] = df['Exterior2nd'].apply(lambda x: change_categories(x, {'AsbShng': 'Ext2_low',  'AsphShn': 'Ext2_low',  'Brk Cmn': 'Ext2_low',  'BrkFace': 'Ext2_low',  'CBlock': 'Ext2_low',  'CmentBd': 'Ext2_high',  'HdBoard': 'Ext2_low',  'ImStucc': 'Ext2_high',  'MetalSd': 'Ext2_low',  'Other': 'Ext2_high',  'Plywood': 'Ext2_low',  'Stone': 'Ext2_low',  'Stucco': 'Ext2_low',  'VinylSd': 'Ext2_high',  'Wd Sdng': 'Ext2_low',  'Wd Shng': 'Ext2_low'}))\n",
    "    df['BldgType'] = df['BldgType'].apply(lambda x: change_categories(x, {'1Fam':'1Fam','TwnhsE':'TwnhsE'}))\n",
    "    df['HouseStyle'] = df['HouseStyle'].apply(lambda x: change_categories(x, {'1Story':'1Story','1.5Fin':'1.5Fin','2Story':'2Level','2.5Fin':'2Level','rare_cat_name':'other_style'}))\n",
    "    df['RoofStyle'] = df['RoofStyle'].apply(lambda x: change_categories(x, {'Hip':'Hip','Shed':'Hip','rare_cat_name':'Gable'}))\n",
    "    df['MasVnrType'] = df['MasVnrType'].apply(lambda x: change_categories(x, {'BrkFace':'Brick','None':'None','BrkCmn':'Brick','Stone':'Stone'}))\n",
    "    df['ExterQual'] = df['ExterQual'].apply(lambda x: change_categories(x, {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}))\n",
    "    #df['ExterCond'] = df['ExterCond'].apply(lambda x: change_categories(x, {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}))\n",
    "    df['Foundation'] = df['Foundation'].apply(lambda x: change_categories(x, {'PConc':'PConc','Wood':'PConc','CBlock':'CBlock','Stone':'CBlock','BrkTil':'BrkTil','Slab':'BrkTil'}))\n",
    "    df['BsmtQual'] = df['BsmtQual'].apply(lambda x: change_categories(x, {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}))\n",
    "    df['HeatingQC'] = df['HeatingQC'].apply(lambda x: change_categories(x, {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}))\n",
    "    df['Electrical'] = df['Electrical'].apply(lambda x: change_categories(x, {'SBrkr':'SBrkr','rare_cat_name':'FuseBox'}))\n",
    "    df['KitchenQual'] = df['KitchenQual'].apply(lambda x: change_categories(x, {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}))\n",
    "    df['FireplaceQu'] = df['FireplaceQu'].apply(lambda x: change_categories(x, {'Po':1,'Fa':2,'TA':3,'Gd':4,'Ex':5}))\n",
    "    df['GarageType'] = df['GarageType'].apply(lambda x: change_categories(x, {'Attchd':'Attchd','BuiltIn':'BuiltIn','Detchd':'Detchd','Basment':'Detchd','2Types':'Detchd','NoGarage':'NoGarage','CarPort':'NoGarage'}))\n",
    "    #df['Fence'] = df['Fence'].apply(lambda x: change_categories(x, {'NoFence':'NoFence','GdPrv':'NoFence','rare_cat_name':'MnPrv'}))\n",
    "    df['SaleType'] = df['SaleType'].apply(lambda x: change_categories(x, {'New':'New','Con':'New','rare_cat_name':'WD'}))\n",
    "    df['SaleCondition'] = df['SaleCondition'].apply(lambda x: change_categories(x, {'Normal':'Normal','Partial':'Partial','rare_cat_name':'Abnormal'}))\n",
    "    \n",
    "    df['TotalFullBath'] = df['TotalFullBath'].apply(lambda x: 1 if x<1 else 4 if x>4 else x)\n",
    "    df['TotalHalfBath'] = df['TotalHalfBath'].apply(lambda x: 0 if x==0 else 1)\n",
    "    df['OtherRmsAbvGrd'] = df['OtherRmsAbvGrd'].apply(lambda x: 1 if x<1 else 8 if x>8 else x)\n",
    "    \n",
    "    # drop features no longer relevant\n",
    "    df.drop(columns=['BsmtUnfSF','2ndFlrSF','BsmtHalfBath'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "normalize_list = pd.read_excel('data/old_features_ames.xlsx', usecols=\"A,K\").dropna()['Feature'].tolist()\n",
    "normalize_list.extend(['TotalFullBath','TotalHalfBath','OtherRmsAbvGrd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = trans_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 52)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "df2 = df.copy()\n",
    "df2[normalize_list] = scaler.fit_transform(df2[normalize_list])\n",
    "cat_list = df2.select_dtypes(exclude=np.number).columns.tolist()\n",
    "df2_cat = pd.get_dummies(df2[cat_list])\n",
    "df2.drop(columns=cat_list, inplace=True)\n",
    "df2 = pd.concat([df2,df2_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 113)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.96962276e-01,  8.84185697e-01, -5.21307189e+20, -4.61181394e+20,\n",
       "        8.23568959e-01])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, df2.drop(columns=['SalePrice']), df2['SalePrice'].apply(lambda x: np.log(x+1)), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.86482672, 0.86319123, 0.87328643, 0.8857346 , 0.84480807])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=60)\n",
    "cross_val_score(rf, df2.drop(columns=['SalePrice']), df2['SalePrice'].apply(lambda x: np.log(x+1)), cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(df2.drop(columns=['SalePrice']), df2['SalePrice'].apply(lambda x: np.log(x+1)), test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01964198060574307"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestRegressor(n_estimators=60)\n",
    "rf2.fit(xtrain, ytrain)\n",
    "mean_squared_error(ytest, rf2.predict(xtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "df3 = df.copy()\n",
    "df3[normalize_list] = scaler.fit_transform(df3[normalize_list])\n",
    "cat_list = df3.select_dtypes(exclude=np.number).columns.tolist()\n",
    "df3_cat = pd.get_dummies(df3[cat_list])\n",
    "df3.drop(columns=cat_list, inplace=True)\n",
    "df3 = pd.concat([df3,df3_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(df3.drop(columns=['SalePrice']), df3['SalePrice'].apply(lambda x: np.log(x+1)), test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1022 samples, validate on 438 samples\n",
      "Epoch 1/3\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 112.5875 - mean_squared_error: 112.5875 - val_loss: 60.0066 - val_mean_squared_error: 60.0066\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/3\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 29.9241 - mean_squared_error: 29.9241 - val_loss: 3.9396 - val_mean_squared_error: 3.9396\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/3\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1.5002 - mean_squared_error: 1.5002 - val_loss: 0.5461 - val_mean_squared_error: 0.5461\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "amesnet = models.Sequential()\n",
    "amesnet.add(layers.Dense(units=64, activation='relu', input_shape=(features_train.shape[1],)))\n",
    "amesnet.add(layers.Dense(units=64, activation='relu'))\n",
    "#amesnet.add(layers.Dense(units=32, activation='relu'))\n",
    "amesnet.add(layers.Dense(units=1))\n",
    "amesnet.compile(loss='mse',\n",
    "                optimizer='RMSprop',\n",
    "                metrics=['mse'])\n",
    "history = amesnet.fit(features_train,\n",
    "                     target_train,\n",
    "                     epochs=3,\n",
    "                     verbose=1,\n",
    "                     batch_size=100,\n",
    "                     validation_data=(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.535653752852738"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "111 ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.534474352733596"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['SalePrice'].apply(lambda x: np.log(x+1)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
